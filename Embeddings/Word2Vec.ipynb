{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step-by-Step Implementation of Word2Vec"
      ],
      "metadata": {
        "id": "3m36wPgHtTSU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkJwx8iPsD8u",
        "outputId": "2d292d60-188e-4956-9403-6eaddca02922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Data Preparation"
      ],
      "metadata": {
        "id": "OFz09w7ItisZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text corpus\n",
        "corpus = [\n",
        "    \"Word embeddings are essential for NLP tasks.\",\n",
        "    \"Word2Vec is a popular word embedding technique.\",\n",
        "    \"Text preprocessing is necessary to clean the data.\",\n",
        "    \"Training Word2Vec models can be done with Gensim.\",\n",
        "    \"Word embeddings capture semantic relationships.\"\n",
        "]"
      ],
      "metadata": {
        "id": "3Gupx1AzsKJ3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Preprocessing"
      ],
      "metadata": {
        "id": "BuKEEH6vtkNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "# Download NLTK stopwords (if not already downloaded)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenize and clean the text\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove punctuation and convert to lowercase\n",
        "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Preprocess the corpus\n",
        "preprocessed_corpus = [preprocess_text(text) for text in corpus]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKOJzZGPsN_Y",
        "outputId": "c9efc2b1-5b79-4b01-e6e9-f490d97a6957"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Training"
      ],
      "metadata": {
        "id": "yj4qpxwJtm1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences=preprocessed_corpus, vector_size=100, window=5, sg=1, min_count=1)"
      ],
      "metadata": {
        "id": "5k3FrBL0sSFx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Embedding Generation"
      ],
      "metadata": {
        "id": "hicmR-QNtqGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the word embedding for a word\n",
        "word_embedding = model.wv['word']\n",
        "print(\"Word Embedding for 'word':\", word_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DVLhzuqsW3P",
        "outputId": "1c319e1c-2275-4791-fc48-0eebc31fd2aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Embedding for 'word': [-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
            " -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
            " -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
            " -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
            "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
            "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
            "  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
            " -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
            "  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
            "  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
            " -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
            " -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
            "  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
            " -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
            "  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
            " -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
            " -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
            " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
            " -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
            "  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
            " -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
            " -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
            " -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
            "  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
            " -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Utilization"
      ],
      "metadata": {
        "id": "ft3bORNSdgSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Finding similar words\n",
        "similar_words = model.wv.most_similar('embedding')\n",
        "print(\"Words similar to 'embedding':\", similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMhdgQqZsaMC",
        "outputId": "e43a835e-5f8f-42c9-dd3e-91ce60f35a50"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to 'embedding': [('preprocessing', 0.31900981068611145), ('done', 0.1747603714466095), ('gensim', 0.11928531527519226), ('necessary', 0.11117951571941376), ('relationships', 0.1088901162147522), ('training', 0.10560833662748337), ('word', 0.09291724115610123), ('models', 0.08058696985244751), ('capture', 0.07913302630186081), ('popular', 0.00484249135479331)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQ3J-oHrsecW"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}