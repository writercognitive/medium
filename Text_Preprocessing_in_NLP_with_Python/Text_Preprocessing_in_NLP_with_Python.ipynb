{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing"
      ],
      "metadata": {
        "id": "-0DaieS5Szra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lowercasing"
      ],
      "metadata": {
        "id": "PA61UIilT1OZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy7-98Pd2cJj",
        "outputId": "85a50b17-7a2c-497b-b048-b08df26474a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the quick brown fox jumps over 2 lazy dogs.\n"
          ]
        }
      ],
      "source": [
        "def lowercase_text(text):\n",
        "    return text.lower()\n",
        "\n",
        "# Test the function\n",
        "input_text = \"The Quick Brown Fox JUMPS Over 2 Lazy Dogs.\"\n",
        "output_text = lowercase_text(input_text)\n",
        "print(output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Punctuations"
      ],
      "metadata": {
        "id": "Qswy4fh2S79V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "# Test the function\n",
        "input_text = \"Hello, my name is John! How are you?\"\n",
        "output_text = remove_punctuations(input_text)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lFJri6S27sD",
        "outputId": "86e2d591-6875-4ce2-b0d7-43d8d1684051"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello my name is John How are you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Special Characters and Numbers"
      ],
      "metadata": {
        "id": "9xyZrIFnTAgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_special_characters_numbers(text):\n",
        "    # Regular expression to remove non-alphabetic characters and numbers\n",
        "    return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "# Test the function\n",
        "input_text = \"Hello, my name is Saif Ali and my age is 25! I was born on 1997-01-10.\"\n",
        "output_text = remove_special_characters_numbers(input_text)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zwVIFc14dpy",
        "outputId": "c2463794-29f3-4f72-e9fa-44acf068f8f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello my name is Saif Ali and my age is  I was born on \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing HTML tags"
      ],
      "metadata": {
        "id": "SOWNo8KRTFi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_html_tags(text):\n",
        "    clean_text = re.sub(r'<.*?>', '', text)\n",
        "    return clean_text\n",
        "\n",
        "# Test the function\n",
        "input_text = \"<p>Hello, <b>my name</b> is <i>John</i>!</p>\"\n",
        "output_text = remove_html_tags(input_text)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-7eDFrw5BWm",
        "outputId": "cde8be57-7404-4034-ebc0-c06bce7d3da3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, my name is John!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing URLs"
      ],
      "metadata": {
        "id": "w40FHM-6TLRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_urls(text):\n",
        "    clean_text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    return clean_text\n",
        "\n",
        "# Test the function\n",
        "input_text = \"Check out my LinkedIn account: https://www.linkedin.com/in/imsaifali/\"\n",
        "output_text = remove_urls(input_text)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhJ85r_A5rwr",
        "outputId": "bd95390f-be3c-4f9f-d3e4-e92b6d46cdb1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check out my LinkedIn account: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Extra Spaces"
      ],
      "metadata": {
        "id": "kHbKl8juTOy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_extra_spaces(text):\n",
        "    clean_text = re.sub(r'\\s+', ' ', text)\n",
        "    return clean_text.strip()\n",
        "\n",
        "# Test the function\n",
        "input_text = \"Hello    there,     how    are   you?\"\n",
        "output_text = remove_extra_spaces(input_text)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrD7jPH36kcM",
        "outputId": "508ad159-dcb4-4ec5-c797-487628277a63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello there, how are you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expanding Contractions"
      ],
      "metadata": {
        "id": "LA3x195kTW7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contraction_mapping = {\n",
        "    \"ain't\": \"is not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"i've\": \"I have\",\n",
        "    \"i'll\": \"I will\",\n",
        "    \"i'd\": \"I would\",\n",
        "    \"i'm\": \"I am\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"here's\": \"here is\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"how's\": \"how is\",\n",
        "}\n",
        "\n",
        "def expand_contractions(text):\n",
        "    words = text.split()\n",
        "    expanded_words = [contraction_mapping[word.lower()] if word.lower() in contraction_mapping else word for word in words]\n",
        "    return ' '.join(expanded_words)\n",
        "\n",
        "# Test the function\n",
        "input_text = \"I can't believe it's already Friday!\"\n",
        "output_text = expand_contractions(input_text)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyDVl8Dc6_R3",
        "outputId": "33ad4dcd-e6a1-4971-f225-464ab6862416"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I cannot believe it is already Friday!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Correction"
      ],
      "metadata": {
        "id": "IuFDZ4iyTYLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def correct_text(text):\n",
        "    blob = TextBlob(text)\n",
        "    corrected_text = blob.correct()\n",
        "    return str(corrected_text)\n",
        "\n",
        "# Test the function\n",
        "input_text = \"I am lerning NLP with Pyhton.\"\n",
        "output_text = correct_text(input_text)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka67b8j57ilx",
        "outputId": "bce7005d-1280-42e2-9c11-2d68a36cdf26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am leaning NLP with Pyhton.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "-NDegWO_Tcrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Test the function\n",
        "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "output_tokens = tokenize_text(input_text)\n",
        "print(output_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov_Go3r07_-M",
        "outputId": "4e13acbc-be5f-44e2-a55c-5c0cee41d143"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Word Removal"
      ],
      "metadata": {
        "id": "17l_2scbTgNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Test the function\n",
        "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "output_text = remove_stopwords(input_text)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8UHdwJj9LBv",
        "outputId": "32c222b1-c494-430d-d8c2-1a43608dc02e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quick brown fox jumps lazy dog.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming"
      ],
      "metadata": {
        "id": "ewLx3rZoTkyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def perform_stemming(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    words = text.split()\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "    return ' '.join(stemmed_words)\n",
        "\n",
        "# Test the function\n",
        "input_text = \"jumps jumping jumped\"\n",
        "output_text = perform_stemming(input_text)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJYTT9yS9zII",
        "outputId": "c99e24bc-3da4-4481-d1eb-f41c8d3a5604"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jump jump jump\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Lemmatization"
      ],
      "metadata": {
        "id": "161rtJzcTo18"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def perform_lemmatization(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = text.split()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Test the function\n",
        "input_text = \"jumps jumping jumped\"\n",
        "output_text = perform_lemmatization(input_text)\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpr-2jSp-WzQ",
        "outputId": "1243d6bd-bb26-4380-d617-395fbe624c41"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jump jumping jumped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O3o1xNhe-42r"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}